import os
import requests
from bs4 import BeautifulSoup
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
from urllib.parse import quote_plus
import re
import time
import random

"""
Guidecom ìƒí’ˆ ê²€ìƒ‰/íŒŒì‹± ëª¨ë“ˆ (app.py ìˆ˜ì • ì—†ì´ ì‚¬ìš©)
- ìš”êµ¬ì‚¬í•­: ë‚®ì€ê°€ê²© 3 + ì¸ê¸°ìƒí’ˆ 4 + í–‰ì‚¬ìƒí’ˆ 3 = ì´ 10ê°œ, ì¤‘ë³µ ì—†ì´ ë°˜í™˜
- ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸ 2ê°€ì§€ ëª¨ë‘ ì§€ì›
  1) GET  https://www.guidecom.co.kr/search/index.html?keyword=...&order=...
  2) POST https://www.guidecom.co.kr/search/list.php (keyword/order/lpp/page)
- ë””ë²„ê¹…: í™˜ê²½ë³€ìˆ˜ GUIDECOM_DEBUG=1 ì´ë©´ ìƒì„¸ ë¡œê·¸ë¥¼ ì½˜ì†”(ìŠ¤íŠ¸ë¦¼ë¦¿ ë¡œê·¸)ë¡œ ì¶œë ¥
"""

# Product í´ë˜ìŠ¤ ì •ì˜
@dataclass
class Product:
    name: str
    price: str
    specifications: str
    product_link: str = ""
    site: str = ""  # "ì»´í“¨ì¡´" ë˜ëŠ” "ê°€ì´ë“œì»´"

class GuidecomParser:
    def __init__(self) -> None:
        self.base_url = "https://www.guidecom.co.kr/search/index.html"
        self.list_url = "https://www.guidecom.co.kr/search/list.php"
        self.ajax_url = "https://www.guidecom.co.kr/ajax/search.php"  # AJAX ì—”ë“œí¬ì¸íŠ¸
        self.alternative_urls = [
            "https://www.guidecom.co.kr/search/",
            "https://www.guidecom.co.kr/shop/search.html", 
            "https://www.guidecom.co.kr/shop/",
        ]
        self.debug = str(os.getenv("GUIDECOM_DEBUG", "0")).lower() in {"1", "true", "yes"}
        self.session = requests.Session()
        self.last_request_time = 0.0
        self._setup_session()

    # ----------------------- Debug helper -----------------------
    def _dbg(self, msg: str) -> None:
        if self.debug:
            print(f"[GUIDECOM][DEBUG] {msg}", flush=True)

    # ----------------------- Session helpers -----------------------
    def _setup_session(self) -> None:
        # ë” ë‹¤ì–‘í•œ User-Agentë¡œ í´ë¼ìš°ë“œ í™˜ê²½ ìš°íšŒ
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        ]
        
        # í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œ ë” ì•ˆì •ì ì¸ í—¤ë” ì„¤ì •
        self.session.headers.update({
            "User-Agent": random.choice(self.user_agents),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Cache-Control": "max-age=0",
        })

    def _update_headers(self) -> None:
        self.session.headers.update({
            "User-Agent": random.choice(self.user_agents),
            "Cache-Control": random.choice(["no-cache", "max-age=0"]),
        })

    def _get_random_delay(self, a: float = 0.35, b: float = 0.9) -> float:
        return random.uniform(a, b)

    def _wait_between_requests(self, min_gap: float = 0.25) -> None:
        now = time.time()
        delta = now - self.last_request_time
        if delta < min_gap:
            time.sleep(min_gap - delta)
        self.last_request_time = time.time()

    def _fix_encoding(self, resp: requests.Response) -> None:
        try:
            # ê°€ì´ë“œì»´ì€ EUC-KR ì‚¬ìš©, ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
            if not resp.encoding or resp.encoding.lower() in ("iso-8859-1", "utf-8"):
                # Content-Typeì—ì„œ charset í™•ì¸
                content_type = resp.headers.get('content-type', '').lower()
                if 'euc-kr' in content_type:
                    resp.encoding = 'euc-kr'
                elif 'charset=euc-kr' in resp.text[:1000].lower():
                    resp.encoding = 'euc-kr'
                else:
                    resp.encoding = resp.apparent_encoding or 'euc-kr'  # ê¸°ë³¸ê°’ì„ euc-krë¡œ
            self._dbg(f"Final encoding set to: {resp.encoding}")
        except Exception as e:
            self._dbg(f"Encoding fix failed: {e}")
            resp.encoding = 'euc-kr'  # ì•ˆì „í•œ ê¸°ë³¸ê°’

    def _make_request(self, url: str, params: Optional[Dict[str, str]] = None, retries: int = 5) -> requests.Response:
        last_exc = None
        for attempt in range(retries):
            try:
                self._update_headers()
                self._wait_between_requests()
                
                # ì¬ì‹œë„ì‹œ ë” ê¸´ ëŒ€ê¸°
                if attempt > 0:
                    delay = self._get_random_delay(2.0 + attempt, 4.0 + attempt)
                    self._dbg(f"Retry {attempt+1}/{retries}, waiting {delay:.2f}s")
                    time.sleep(delay)
                
                # í´ë¼ìš°ë“œ í™˜ê²½ì„ ìœ„í•œ ì¶”ê°€ í—¤ë”
                extra_headers = {
                    "Referer": "https://www.google.com/",
                    "Origin": "https://www.guidecom.co.kr" if "guidecom.co.kr" in url else None
                }
                extra_headers = {k: v for k, v in extra_headers.items() if v}
                
                self._dbg(f"GET {url} params={params} extra_headers={extra_headers}")
                
                resp = self.session.get(
                    url, 
                    params=params, 
                    headers=extra_headers,
                    timeout=45,  # ë” ê¸´ íƒ€ì„ì•„ì›ƒ
                    allow_redirects=True,
                    verify=True  # SSL ê²€ì¦ í™œì„±í™”
                )
                
                self._fix_encoding(resp)
                self._dbg(f"GET status={resp.status_code} encoding={resp.encoding} len={len(resp.text)}")
                
                # ì‘ë‹µ ìƒíƒœ ì²´í¬
                if resp.status_code == 200:
                    # ë§¤ìš° ê´€ëŒ€í•œ ì¡°ê±´ìœ¼ë¡œ ë³€ê²½
                    if len(resp.text) > 50:  # ìµœì†Œ 50ìë§Œ ìˆìœ¼ë©´ í†µê³¼
                        return resp
                    else:
                        self._dbg(f"Response too short: {len(resp.text)} chars")
                elif resp.status_code in [301, 302, 303, 307, 308]:
                    self._dbg(f"Redirect detected: {resp.status_code}")
                    return resp  # ë¦¬ë‹¤ì´ë ‰íŠ¸ë„ í—ˆìš©
                else:
                    self._dbg(f"HTTP Error: {resp.status_code}")
                    self._dbg(f"Response Headers: {dict(resp.headers)}")
                    self._dbg(f"Response Text (first 300 chars): {resp.text[:300]}")
                    
            except requests.exceptions.Timeout:
                self._dbg(f"TIMEOUT on attempt {attempt+1}/{retries}")
                last_exc = RuntimeError(f"Timeout after {45}s")
            except requests.exceptions.ConnectionError as e:
                self._dbg(f"CONNECTION ERROR on attempt {attempt+1}/{retries}: {e}")
                last_exc = e
            except requests.RequestException as e:
                self._dbg(f"REQUEST ERROR on attempt {attempt+1}/{retries}: {e}")
                last_exc = e
                
        self._dbg(f"All {retries} attempts failed")
        raise last_exc if last_exc else RuntimeError("ìš”ì²­ ì‹¤íŒ¨")

    def _post_list(self, keyword: str, order: str, page: int = 1, lpp: int = 30, use_computer_parts_filter: bool = True) -> Optional[BeautifulSoup]:
        """list.phpë¡œ ì§ì ‘ POSTí•˜ì—¬ goods-row HTML ì¡°ê°ì„ ë°›ëŠ”ë‹¤."""
        try:
            self._update_headers()
            self._wait_between_requests()
            referer = f"https://www.guidecom.co.kr/search/?keyword={quote_plus(keyword)}&order={order}"
            headers = {"Referer": referer}
            data = {"keyword": keyword, "order": order, "lpp": lpp, "page": page, "y": 0}
            
            # ì»´í“¨í„°ì£¼ìš”ë¶€í’ˆ ì¹´í…Œê³ ë¦¬ í•„í„° ì ìš©
            if use_computer_parts_filter:
                # í‚¤ì›Œë“œì— ë”°ë¼ ê´€ë ¨ì„± ë†’ì€ ì¹´í…Œê³ ë¦¬ë¶€í„° ì‹œë„
                keyword_lower = keyword.lower()
                
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ ë§¤í•‘
                if any(k in keyword_lower for k in ["cpu", "í”„ë¡œì„¸ì„œ", "processor", "intel", "amd", "ë¼ì´ì  ", "ryzen", "ì¸í…”"]):
                    priority_categories = ["8800"]  # CPU
                elif any(k in keyword_lower for k in ["ë©”ì¸ë³´ë“œ", "ë§ˆë”ë³´ë“œ", "motherboard", "mainboard", "ë³´ë“œ"]):
                    priority_categories = ["8801"]  # ë©”ì¸ë³´ë“œ
                elif any(k in keyword_lower for k in ["ë©”ëª¨ë¦¬", "ram", "ddr", "ddr4", "ddr5"]):
                    priority_categories = ["8802"]  # ë©”ëª¨ë¦¬
                elif any(k in keyword_lower for k in ["ê·¸ë˜í”½", "gpu", "rtx", "gtx", "radeon", "rx", "nvidia", "ì§€í¬ìŠ¤", "vga"]):
                    priority_categories = ["8803"]  # ê·¸ë˜í”½ì¹´ë“œ
                elif any(k in keyword_lower for k in ["hdd", "í•˜ë“œë””ìŠ¤í¬", "í•˜ë“œ", "western digital", "wd", "seagate", "ì‹œê²Œì´íŠ¸", "toshiba", "ë„ì‹œë°”"]):
                    priority_categories = ["8804"]  # HDD ìš°ì„ 
                elif any(k in keyword_lower for k in ["ssd", "solid state", "nvme", "m.2", "crucial", "samsung"]):
                    priority_categories = ["8855"]  # SSD
                elif any(k in keyword_lower for k in ["íŒŒì›Œ", "power", "psu", "íŒŒì›Œì„œí”Œë¼ì´", "ì „ì›ê³µê¸‰", "80plus"]):
                    priority_categories = ["8806"]  # íŒŒì›Œì„œí”Œë¼ì´
                elif any(k in keyword_lower for k in ["ì¼€ì´ìŠ¤", "case", "ì»´í“¨í„°ì¼€ì´ìŠ¤", "pcì¼€ì´ìŠ¤", "íƒ€ì›Œ"]):
                    priority_categories = ["8807"]  # ì¼€ì´ìŠ¤
                elif any(k in keyword_lower for k in ["ì¿¨ëŸ¬", "cooler", "cpuì¿¨ëŸ¬", "ìˆ˜ë­", "ìˆ˜ëƒ‰", "ê³µë­"]):
                    priority_categories = ["8805"]  # CPUì¿¨ëŸ¬
                elif any(k in keyword_lower for k in ["ëª¨ë‹ˆí„°", "monitor", "ë””ìŠ¤í”Œë ˆì´", "display"]):
                    priority_categories = ["8808"]  # ëª¨ë‹ˆí„°
                elif any(k in keyword_lower for k in ["í‚¤ë³´ë“œ", "keyboard", "ê¸°ê³„ì‹"]):
                    priority_categories = ["8809"]  # í‚¤ë³´ë“œ  
                elif any(k in keyword_lower for k in ["ë§ˆìš°ìŠ¤", "mouse", "ê²Œì´ë°ë§ˆìš°ìŠ¤"]):
                    priority_categories = ["8810"]  # ë§ˆìš°ìŠ¤
                elif "ë””ìŠ¤í¬" in keyword_lower and not any(k in keyword_lower for k in ["hdd", "í•˜ë“œë””ìŠ¤í¬", "í•˜ë“œ"]):
                    # "ë””ìŠ¤í¬"ë§Œ ìˆê³  HDD ê´€ë ¨ í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš°
                    priority_categories = ["8855", "8804"]  # SSD ë¨¼ì €, ê·¸ë‹¤ìŒ HDD
                else:
                    # ì¼ë°˜ ê²€ìƒ‰: ì£¼ìš” ì»´í“¨í„° ë¶€í’ˆ ì¹´í…Œê³ ë¦¬ë“¤
                    priority_categories = ["8855", "8803", "8802", "8800", "8801", "8804"]
                
                self._dbg(f"Priority categories for '{keyword}': {priority_categories}")
                
                # ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ë¶€í„° ê²€ìƒ‰
                for cid in priority_categories:
                    try:
                        data_with_cid = data.copy()
                        data_with_cid["cid"] = cid
                        self._dbg(f"POST {self.list_url} with cid={cid}")
                        resp = self.session.post(self.list_url, data=data_with_cid, headers=headers, timeout=30)
                        self._fix_encoding(resp)
                        
                        if resp.status_code == 200 and len(resp.text) > 100:
                            soup = BeautifulSoup(resp.text, "lxml")
                            rows = soup.find_all("div", class_="goods-row")
                            self._dbg(f"Category {cid}: found {len(rows)} products")
                            
                            if len(rows) > 0:  # ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°”ë¡œ ì‚¬ìš©
                                self._dbg(f"Using category {cid} with {len(rows)} products")
                                return soup
                                
                        # ì¹´í…Œê³ ë¦¬ë³„ ìš”ì²­ ê°„ê²©
                        self._wait_between_requests(0.1)
                        
                    except Exception as e:
                        self._dbg(f"Category {cid} failed: {e}")
                        continue
                
                self._dbg("No results found in priority categories, trying fallback")
            
            # ì»´í“¨í„° ë¶€í’ˆ í•„í„°ê°€ ê²°ê³¼ë¥¼ ëª» ì°¾ê±°ë‚˜ ë¹„í™œì„±í™”ëœ ê²½ìš° ê¸°ë³¸ ê²€ìƒ‰
            self._dbg(f"POST {self.list_url} data={data} referer={referer}")
            resp = self.session.post(self.list_url, data=data, headers=headers, timeout=30)
            self._fix_encoding(resp)
            self._dbg(f"POST status={resp.status_code} encoding={resp.encoding} len={len(resp.text)}")
            if resp.status_code == 200 and len(resp.text) > 100:
                soup = BeautifulSoup(resp.text, "lxml")
                rows = soup.find_all("div", class_="goods-row")
                self._dbg(f"POST parsed goods-row={len(rows)}")
                
                # ë””ë²„ê·¸: ì²« ë²ˆì§¸ ìƒí’ˆì˜ HTML êµ¬ì¡° í™•ì¸
                if self.debug and rows:
                    self._dbg(f"=== FIRST PRODUCT HTML ===")
                    self._dbg(f"First row HTML: {str(rows[0])[:1000]}")
                    
                return soup
        except requests.RequestException as e:
            self._dbg(f"POST exception: {e}")
            return None
        return None
    
    def _try_alternative_methods(self, keyword: str, order: str) -> Optional[BeautifulSoup]:
        """ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ìƒí’ˆ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹œë„"""
        methods = [
            ("POST list.php with computer parts filter", lambda: self._post_list(keyword, order, use_computer_parts_filter=True)),
            ("POST list.php", lambda: self._post_list(keyword, order, use_computer_parts_filter=False)),
            ("GET with params", lambda: self._get_with_params(keyword, order)),
            ("Alternative URLs", lambda: self._try_alternative_urls(keyword, order))
        ]
        
        for method_name, method_func in methods:
            self._dbg(f"Trying method: {method_name}")
            try:
                result = method_func()
                if result and result.find_all("div", class_="goods-row"):
                    self._dbg(f"Success with method: {method_name}")
                    return result
            except Exception as e:
                self._dbg(f"Method {method_name} failed: {e}")
                
        return None
    
    def _get_with_params(self, keyword: str, order: str) -> Optional[BeautifulSoup]:
        """GET ìš”ì²­ìœ¼ë¡œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°"""
        try:
            params = {"keyword": keyword, "order": order}
            resp = self._make_request(self.base_url, params=params)
            soup = BeautifulSoup(resp.text, "lxml")
            return soup
        except Exception as e:
            self._dbg(f"GET with params failed: {e}")
            return None
    
    def _try_alternative_urls(self, keyword: str, order: str) -> Optional[BeautifulSoup]:
        """ëŒ€ì²´ URLë“¤ ì‹œë„"""
        for alt_url in self.alternative_urls:
            try:
                self._dbg(f"Trying alternative URL: {alt_url}")
                params = {"keyword": keyword, "order": order, "q": keyword}
                resp = self._make_request(alt_url, params=params)
                soup = BeautifulSoup(resp.text, "lxml")
                rows = soup.find_all("div", class_="goods-row")
                if rows:
                    self._dbg(f"Found {len(rows)} products in {alt_url}")
                    return soup
            except Exception as e:
                self._dbg(f"Alternative URL {alt_url} failed: {e}")
        return None

    # ----------------------- Parsing helpers -----------------------
    def _find_goods_list(self, soup: BeautifulSoup):
        # 1ìˆœìœ„: ê¸°ë³¸ goods-list
        gl = soup.find(id="goods-list")
        if gl and gl.find_all("div", class_="goods-row"):
            self._dbg("Found products in #goods-list")
            return gl
            
        # 2ìˆœìœ„: placeholder ë‚´ë¶€
        placeholder = soup.find(id="goods-placeholder")
        if placeholder:
            inner = placeholder.find(id="goods-list")
            if inner and inner.find_all("div", class_="goods-row"):
                self._dbg("Found products in #goods-placeholder > #goods-list")
                return inner
        
        # 3ìˆœìœ„: ë‹¤ì–‘í•œ ì»¨í…Œì´ë„ˆ ID/í´ë˜ìŠ¤ ì‹œë„
        containers = [
            soup.find(id="product-list"),
            soup.find(id="search-results"),
            soup.find(class_="product-list"),
            soup.find(class_="search-results"),
            soup.find(class_="goods-container"),
            soup.find(class_="product-container")
        ]
        
        for container in containers:
            if container and container.find_all("div", class_="goods-row"):
                self._dbg(f"Found products in alternative container: {container.get('id') or container.get('class')}")
                return container
        
        # 4ìˆœìœ„: ì „ì²´ soupì—ì„œ goods-rowê°€ ìˆëŠ”ì§€ í™•ì¸
        if soup.find_all("div", class_="goods-row"):
            self._dbg("Found goods-row in root soup")
            return soup
        
        # 5ìˆœìœ„: ë‹¤ë¥¸ ê°€ëŠ¥í•œ ìƒí’ˆ ì»¨í…Œì´ë„ˆë“¤ ì‹œë„
        alternative_selectors = [
            "div[class*='product']",
            "div[class*='item']", 
            "div[class*='goods']",
            ".product-item",
            ".search-item",
            ".list-item"
        ]
        
        for selector in alternative_selectors:
            items = soup.select(selector)
            if items:
                self._dbg(f"Found {len(items)} items with selector: {selector}")
                # ê°€ì§œ goods-row êµ¬ì¡° ìƒì„±
                fake_container = soup.new_tag("div")
                for item in items[:20]:  # ìµœëŒ€ 20ê°œ
                    item['class'] = item.get('class', []) + ['goods-row']
                    fake_container.append(item)
                return fake_container
        
        self._dbg("No product containers found anywhere")
        return soup

    def _extract_text(self, el) -> str:
        return el.get_text(" ", strip=True) if el else ""

    def _parse_price(self, text: str) -> str:
        digits = re.sub(r"[^\d]", "", text or "")
        if not digits:
            return ""
        return f"{int(digits):,}ì›"

    def _parse_product_item(self, row) -> Optional[Product]:
        try:
            # ë””ë²„ê·¸: ì „ì²´ row HTML êµ¬ì¡° ì¶œë ¥
            if self.debug:
                self._dbg(f"=== ROW HTML DEBUG ===")
                self._dbg(f"Row classes: {row.get('class', [])}")
                self._dbg(f"Row HTML (first 500 chars): {str(row)[:500]}")
            
            # ì´ë¦„: ì—¬ëŸ¬ ì„ íƒì ì‹œë„
            name_selectors = [
                ".desc .goodsname1",
                ".desc h4.title a", 
                "h4.title a",
                ".desc .title a",
                ".title a",
                ".desc a",
                "a"
            ]
            
            name_el = None
            product_link = ""
            for selector in name_selectors:
                name_el = row.select_one(selector)
                if name_el:
                    self._dbg(f"Found name with selector: {selector}")
                    # ë§í¬ URL ì¶”ì¶œ
                    if name_el.get('href'):
                        href = name_el.get('href')
                        if href.startswith('/'):
                            product_link = f"https://www.guidecom.co.kr{href}"
                        elif href.startswith('http'):
                            product_link = href
                        else:
                            product_link = f"https://www.guidecom.co.kr/{href}"
                    break
                    
            name = self._extract_text(name_el)
            if not name:
                self._dbg("=== NAME NOT FOUND ===")
                self._dbg(f"Available elements: {[tag.name for tag in row.find_all()]}")
                self._dbg(f"All text in row: {row.get_text(' ', strip=True)}")
                return None
                
            self._dbg(f"Product name: {name}")
            
            # ìŠ¤í™ ì¶”ì¶œ: ë” ê´‘ë²”ìœ„í•œ ì„ íƒì
            spec_selectors = [
                ".desc .feature",
                ".feature", 
                ".desc .spec",
                ".spec",
                ".desc .description",
                ".description",
                ".desc .summary",
                ".summary",
                ".desc .info",
                ".info",
                ".desc ul",
                ".desc p",
                ".goodsinfo"
            ]
            
            specs = ""
            for selector in spec_selectors:
                spec_el = row.select_one(selector)
                if spec_el:
                    specs = self._extract_text(spec_el)
                    if specs and specs != name:
                        self._dbg(f"Found specs with selector {selector}: {specs[:100]}")
                        break
                        
            if not specs:
                # ë§ˆì§€ë§‰ ì‹œë„: .desc ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ
                desc_el = row.select_one(".desc")
                if desc_el:
                    # ë§í¬ í…ìŠ¤íŠ¸ ì œê±°í•˜ê³  ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    desc_copy = desc_el.__copy__()
                    for a_tag in desc_copy.find_all('a'):
                        a_tag.decompose()
                    specs = self._extract_text(desc_copy).strip()
                    if specs:
                        self._dbg(f"Extracted specs from .desc (no links): {specs[:100]}")
                        
            if not specs:
                self._dbg("=== SPECS NOT FOUND ===")
                desc_el = row.select_one(".desc")
                if desc_el:
                    self._dbg(f"Desc HTML: {str(desc_el)[:300]}")
                else:
                    self._dbg("No .desc element found")
                    
            # ê°€ê²© ì¶”ì¶œ: ë” ë‹¤ì–‘í•œ ì„ íƒì
            price_selectors = [
                ".prices .price-large span",
                ".price-large span",
                ".price-large",
                ".prices .price span",
                ".price span", 
                ".price",
                ".cost",
                "[class*='price']"
            ]
            
            price = ""
            for selector in price_selectors:
                price_el = row.select_one(selector)
                if price_el:
                    price = self._parse_price(self._extract_text(price_el))
                    if price:
                        self._dbg(f"Found price with selector {selector}: {price}")
                        break
                        
            if not price:
                self._dbg("=== PRICE NOT FOUND ===")
                self._dbg(f"Available elements with 'price' in class: {[str(el)[:100] for el in row.find_all(class_=lambda x: x and 'price' in str(x).lower())]}")
                
            return Product(name=name, price=price or "ê°€ê²© ì •ë³´ ì—†ìŒ", specifications=specs or "ì‚¬ì–‘ ì •ë³´ ì—†ìŒ", product_link=product_link, site="ê°€ì´ë“œì»´")
        except Exception as e:
            self._dbg(f"_parse_product_item exception: {e}")
            import traceback
            self._dbg(f"Traceback: {traceback.format_exc()}")
            return None

    # ----------------------- Manufacturer helpers -----------------------
    def _normalize_brand(self, text: str) -> str:
        t = (text or "").lower()
        t = re.sub(r"[\s._/-]+", " ", t).strip()
        aliases = {
            "wd": "western digital",
            "ì›¨ìŠ¤í„´ ë””ì§€í„¸": "western digital",
            "ì—ì´ìˆ˜ìŠ¤": "asus",
            "ê¸°ê°€ë°”ì´íŠ¸": "gigabyte",
            "ì¡°í…": "zotac",
            "ì—”ë¹„ë””ì•„": "nvidia",
            "ì‚¼ì„±": "ì‚¼ì„±ì „ì",
            "samsung": "ì‚¼ì„±ì „ì",
            "g skill": "gskill",
            "tp-link": "tp link",
        }
        return aliases.get(t, t)

    def _extract_manufacturer(self, product_name: str) -> Optional[str]:
        if not product_name:
            return None
        
        self._dbg(f"Extracting manufacturer from: '{product_name}'")
        
        # ëŒ€ê´„í˜¸ ì œê±° ë° ì •ë¦¬
        text = re.sub(r"\[[^\]]+\]", " ", product_name)
        text = re.sub(r"\s+", " ", text).strip()
        words = text.split()
        
        if not words:
            self._dbg("No words found after cleaning")
            return None
            
        self._dbg(f"Words after cleaning: {words}")
        
        # ê±´ë„ˆë›¸ ë‹¨ì–´ë“¤ - ë” í¬ê´„ì ìœ¼ë¡œ í™•ì¥
        skip = {
            "ì‹ ì œí’ˆ", "ì‹ ìƒí’ˆ", "ê³µì‹ì¸ì¦", "ë³‘í–‰ìˆ˜ì…", "ë²Œí¬", "ì •í’ˆ", "ìŠ¤í˜ì…œ", "í•œì •íŒ",
            "8ì›”", "7ì›”", "6ì›”", "9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”", "3ì›”", "4ì›”", "5ì›”",
            "ìƒˆìƒí’ˆ", "ë¦¬í¼", "ì¤‘ê³ ", "ì „ì‹œ", "ê°œë´‰", "ë°•ìŠ¤", "ì˜¤í”ˆë°•ìŠ¤", "ë¦¬í¼ë¹„ì‹œ",
            "í• ì¸", "íŠ¹ê°€", "ì„¸ì¼", "ì´ë²¤íŠ¸", "í”„ë¡œëª¨ì…˜", "í•œì •", "ë¬´ë£Œë°°ì†¡", "ë‹¹ì¼ë°œì†¡"
        }
        
        i = 0
        while i < len(words):
            word = words[i]
            self._dbg(f"Checking word '{word}' (index {i})")
            
            # ì •í™•í•œ ë§¤ì¹˜ ë˜ëŠ” ë¶€ë¶„ ë§¤ì¹˜ í™•ì¸
            should_skip = False
            for skip_word in skip:
                if word == skip_word or skip_word in word or word in skip_word:
                    should_skip = True
                    self._dbg(f"Skipping word '{word}' (matched with '{skip_word}')")
                    break
                    
            if not should_skip:
                break
            i += 1
            
        if i >= len(words):
            self._dbg("All words were skipped, no manufacturer found")
            return None
            
        manufacturer = words[i]
        self._dbg(f"Found manufacturer candidate: '{manufacturer}'")
        
        # 2ë‹¨ì–´ ë¸Œëœë“œ ê²°í•©(Western Digital, TP LINK ë“±)
        if i + 1 < len(words):
            pair = f"{manufacturer} {words[i+1]}"
            normalized_pair = self._normalize_brand(pair)
            if normalized_pair in {"western digital", "tp link", "g skill", "team group"}:
                manufacturer = pair
                self._dbg(f"Combined into 2-word brand: '{manufacturer}'")
                
        self._dbg(f"Final manufacturer: '{manufacturer}'")
        return manufacturer

    def _extract_manufacturer_from_row(self, row) -> Optional[str]:
        name_el = row.select_one(".desc .goodsname1")
        if not name_el:
            name_el = row.select_one(".desc h4.title a") or row.select_one("h4.title a")
        name = self._extract_text(name_el)
        maker = self._extract_manufacturer(name)
        if self.debug:
            self._dbg(f"NAME='{name[:80]}' -> MFR='{maker}'")
        return maker

    def _filter_by_maker(self, product: Product, maker_codes: List[str]) -> bool:
        if not maker_codes:
            return True
        manufacturer = self._extract_manufacturer(product.name)
        if not manufacturer:
            return False
        man_norm = self._normalize_brand(manufacturer)
        sel_norms = [self._normalize_brand(code.replace("_", " ")) for code in maker_codes]
        for sel in sel_norms:
            if man_norm == sel or man_norm in sel or sel in man_norm:
                return True
        brand_pairs = [
            ("western digital", ["wd", "western", "digital"]),
            ("ì‚¼ì„±ì „ì", ["samsung", "ì‚¼ì„±"]),
            ("asus", ["ì—ì´ìˆ˜ìŠ¤"]),
            ("gigabyte", ["ê¸°ê°€ë°”ì´íŠ¸"]),
            ("zotac", ["ì¡°í…"]),
            ("nvidia", ["ì—”ë¹„ë””ì•„"]),
            ("tp link", ["tp-link"]),
        ]
        for canonical, aliases in brand_pairs:
            if man_norm == canonical and any(a == sel for sel in sel_norms for a in aliases):
                return True
            if man_norm in aliases and any(sel == canonical for sel in sel_norms):
                return True
        return False

    # ----------------------- Public API -----------------------
    def get_search_options(self, keyword: str) -> List[Dict[str, str]]:
        """
        ì œì¡°ì‚¬ í›„ë³´ë¥¼ ìµœëŒ€ 8ê°œê¹Œì§€ ë°˜í™˜.
        1) list.php POST ê²°ê³¼ì—ì„œ ìš°ì„  ì¶”ì¶œ
        2) ì‹¤íŒ¨ ì‹œ ê²€ìƒ‰ í˜ì´ì§€(GET)ì—ì„œ ë³´ì¡° ì¶”ì¶œ
        ë””ë²„ê¹… ì¶œë ¥:
          - goods-row ê°œìˆ˜
          - ìƒ˜í”Œ ì œí’ˆëª…ë“¤, ì œí’ˆëª…->ì œì¡°ì‚¬ ë§¤í•‘ ëª‡ ê°œ
        """
        manufacturers: List[str] = []
        seen = set()
        try:
            # 1) ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ìƒí’ˆ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹œë„
            soup = self._try_alternative_methods(keyword, "reco_goods")
            
            if not soup:
                self._dbg("All methods failed, trying fallback approaches")
                # ë§ˆì§€ë§‰ ì‹œë„: ë‹¨ìˆœ GET ìš”ì²­
                try:
                    params = {"keyword": keyword}
                    resp = self._make_request(self.base_url, params=params)
                    soup = BeautifulSoup(resp.text, "lxml")
                except Exception as e:
                    self._dbg(f"Fallback GET failed: {e}")
                    return []
                    
            container = self._find_goods_list(soup) if soup else None
            rows = container.find_all("div", class_="goods-row") if container else []

            self._dbg(f"get_search_options: goods-row count={len(rows)}")
            
            # ë””ë²„ê·¸: HTML êµ¬ì¡° í™•ì¸
            if self.debug and soup:
                self._dbg(f"=== SOUP CONTENT SAMPLE ===")
                body_text = soup.get_text()[:1000] if soup.body else "No body found"
                self._dbg(f"Body text sample: {body_text}")
                
            sample_names: List[str] = []

            for idx, row in enumerate(rows[:80]):
                name_el = row.select_one(".desc .goodsname1") or row.select_one(".desc h4.title a") or row.select_one("h4.title a")
                nm = self._extract_text(name_el)
                if self.debug and idx < 10:
                    sample_names.append(nm)
                maker = self._extract_manufacturer(nm)
                if maker and maker not in seen:
                    manufacturers.append(maker)
                    seen.add(maker)
                if len(manufacturers) >= 8:
                    break

            if self.debug:
                self._dbg("sample names: " + " | ".join(sample_names))
                self._dbg("manufacturers: " + ", ".join(manufacturers))

            def sort_key(x: str):
                xn = self._normalize_brand(x)
                return (0 if re.search(r"[ê°€-í£]", x) else 1, xn)

            return [{"name": m, "code": self._normalize_brand(m).replace(" ", "_")} for m in sorted(manufacturers, key=sort_key)]
        except Exception as e:
            self._dbg(f"get_search_options exception: {e}")
            return []

    def _resolve_order_param(self, sort_type: str) -> str:
        mapping = {
            "price_0": "price_0",
            "ë‚®ì€ê°€ê²©": "price_0",
            "priceasc": "price_0",
            "reco_goods": "reco_goods",
            "ì¸ê¸°ìƒí’ˆ": "reco_goods",
            "opiniondesc": "reco_goods",
            "event_goods": "event_goods",
            "í–‰ì‚¬ìƒí’ˆ": "event_goods",
            "savedesc": "event_goods",
        }
        k = (sort_type or "").lower()
        return mapping.get(k, "reco_goods")

    def search_products(self, keyword: str, sort_type: str, maker_codes: List[str], limit: int = 5) -> List[Product]:
        """ë‹¨ì¼ ì •ë ¬ ê¸°ì¤€ìœ¼ë¡œ ì œí’ˆ ìµœëŒ€ `limit`ê°œ ë°˜í™˜ (list.php ìš°ì„ )."""
        try:
            order = self._resolve_order_param(sort_type)
            # 1) ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì‹œë„
            soup = self._try_alternative_methods(keyword, order)
            
            if soup:
                container = self._find_goods_list(soup)
                rows = container.find_all("div", class_="goods-row") if container else []
            else:
                rows = []
                
            self._dbg(f"search_products: order={order} rows={len(rows)}")
            out: List[Product] = []
            for row in rows:
                p = self._parse_product_item(row)
                if not p:
                    continue
                if not self._filter_by_maker(p, maker_codes):
                    continue
                out.append(p)
                if len(out) >= limit:
                    break
            self._dbg(f"search_products: returned={len(out)}")
            return out
        except Exception as e:
            self._dbg(f"search_products exception: {e}")
            return []

    def get_unique_products(self, keyword: str, maker_codes: List[str]) -> List[Product]:
        """ë‚®ì€ê°€ê²© 3 + ì¸ê¸°ìƒí’ˆ 4 + í–‰ì‚¬ìƒí’ˆ 3 = ì´ 10ê°œ(ì¤‘ë³µ ì œê±°)."""
        buckets: List[Tuple[str, int]] = [
            ("price_0", 3),     # ë‚®ì€ê°€ê²©
            ("reco_goods", 4),  # ì¸ê¸°ìƒí’ˆ
            ("event_goods", 3), # í–‰ì‚¬ìƒí’ˆ
        ]
        results: List[Product] = []
        seen_names = set()

        for order, want in buckets:
            candidates = self.search_products(keyword, order, maker_codes, limit=50)
            took = 0
            for p in candidates:
                if p.name in seen_names:
                    continue
                results.append(p)
                seen_names.add(p.name)
                took += 1
                if took >= want:
                    break
        self._dbg(f"get_unique_products: total={len(results)} unique names={len(seen_names)}")
        
        # ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ë” ìœ ìš©í•œ ì•ˆë‚´ ë©”ì‹œì§€ ë°˜í™˜
        if not results:
            self._dbg("No products found, returning helpful guidance")
            return [
                Product(
                    name="ğŸ” ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤",
                    price="ì•ˆë‚´", 
                    specifications="ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì„¸ìš”. ì˜ˆ: SSD, ê·¸ë˜í”½ì¹´ë“œ, ë©”ëª¨ë¦¬, ë©”ì¸ë³´ë“œ ë“±",
                    product_link="",
                    site="ê°€ì´ë“œì»´"
                ),
                Product(
                    name="ğŸŒ ì„œë²„ ì—°ê²° ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                    price="í•´ê²°ë°©ë²•", 
                    specifications="1) ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„ 2) ê²€ìƒ‰ì–´ë¥¼ ë‹¨ìˆœí•˜ê²Œ ì…ë ¥ 3) ë¸Œëœë“œëª… ëŒ€ì‹  ì œí’ˆ ì¢…ë¥˜ë¡œ ê²€ìƒ‰",
                    product_link="",
                    site="ê°€ì´ë“œì»´"
                ),
                Product(
                    name="ğŸ“ ê²€ìƒ‰ íŒ",
                    price="ë„ì›€ë§", 
                    specifications="â€¢ 'ì‚¼ì„± SSD' ëŒ€ì‹  'SSD'ë¡œ ê²€ìƒ‰ â€¢ ì˜ë¬¸ë³´ë‹¤ëŠ” í•œê¸€ ê²€ìƒ‰ì–´ ê¶Œì¥ â€¢ ë„ˆë¬´ êµ¬ì²´ì ì¸ ëª¨ë¸ëª…ë³´ë‹¤ëŠ” ì¼ë°˜ì ì¸ ì œí’ˆêµ°ìœ¼ë¡œ ê²€ìƒ‰",
                    product_link="",
                    site="ê°€ì´ë“œì»´"
                )
            ]
            
        return results[:10]
